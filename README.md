<h1>Overview</h1>
This project aims to efficiently remove duplicate data copies using a combination of linked lists and hashing. 
By utilizing these data structures, we ensure that only a single unique instance of data remains on a storage device. 
The process involves guaranteeing that the single instance is indeed the only file by thoroughly checking for duplications. 
The primary goal is to minimize the use of resources employed in storing and managing data, optimizing storage efficiency.


<h6>{go to about.txt for more info}</h6>

<h1>Features</h1>

1. Duplicate Removal:
DeDuplify employs a linked list and hashing mechanism to identify and remove duplicate instances of data. This ensures that only one unique copy of the data is retained, minimizing redundancy.

2. Data Integrity Verification :
To guarantee that the single remaining instance is truly the only file, DEDUPLIFY performs a thorough check for duplication. This verification step ensures data integrity and reliability.

3. Resource Optimization :
The project is designed with a focus on minimizing the use of resources for storing and managing data. This optimization contributes to efficient utilization of storage devices and overall system resources.


<h1>Prerequisites</h1>

Before using DEDUPLIFY, make sure you have the following installed:
Python (version 3.6 or higher)

<h1>Installation</h1>

Clone the repository: git clone https://github.com/your-username/deduplify.git

Navigate to the project directory: cd deduplify

Run the application: python deduplify.py

<h1>Usage</h1>

- Launch the application using the provided command.
- Follow the on-screen prompts to provide input and configure the deduplication process.
- Sit back and let DEDUPLIFY work its magic! 
- The application will perform duplicate removal and data integrity verification.
